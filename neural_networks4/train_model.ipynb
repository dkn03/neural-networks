{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import RNN, LSTM, GRU\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from ray import tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from functools import partial\n",
    "\n",
    "from model import *\n",
    "from dataset import MyDataset\n",
    "\n",
    "\n",
    "from utils import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../nn4_data/UCI HAR Dataset/train/Inertial Signals/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    files = os.listdir(data_path)\n",
    "    file_path = data_path + files[0]\n",
    "    train_data = torch.tensor(genfromtxt(file_path)).unsqueeze(2)\n",
    "    for file in os.listdir(train_path)[1:]:\n",
    "        file_path = data_path + file\n",
    "        new_vector = torch.tensor(genfromtxt(file_path)).unsqueeze(2)\n",
    "        train_data = torch.concat((train_data, new_vector), 2)\n",
    "\n",
    "    return train_data.to(dtype=torch.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7352, 128, 9])\n"
     ]
    }
   ],
   "source": [
    "x_data = read_data(train_path).to(device=device)\n",
    "print(x_data.shape)\n",
    "y_path = \"../nn4_data/UCI HAR Dataset/train/y_train.txt\"\n",
    "y_data = (torch.tensor(genfromtxt(y_path)) - 1).to(device=device)\n",
    "\n",
    "full_dataset = MyDataset(x_data, y_data)\n",
    "train_dataset, validation_dataset = random_split(full_dataset, (0.8, 0.2))\n",
    "train_loader, validation_loader = DataLoader(train_dataset, batch_size=8), DataLoader(validation_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, scheduler, model, loss_fn, train_loader, validation_loader, ):\n",
    "\n",
    "    best_loss = None\n",
    "    counter = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for data, label in train_loader:\n",
    "            hidden = model.init_hidden().to(device=device)\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = loss_fn(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        summary_loss = 0\n",
    "        for data, label in validation_loader:\n",
    "            hidden = model.init_hidden().to(device=device)        \n",
    "            output, hidden = model(data, hidden)\n",
    "            summary_loss += loss_fn(output, label)\n",
    "\n",
    "        validation_loss = summary_loss / len(validation_loader)\n",
    "\n",
    "        if best_loss and validation_loss > best_loss:\n",
    "            counter += 1\n",
    "            if counter == 5:\n",
    "                print(f\"Early stop on epoch {epoch}\")\n",
    "                break\n",
    "        else:\n",
    "            counter = 0\n",
    "            best_loss = validation_loss\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "\n",
    "            print('{} Epoch {}, Training loss {}, Validation loss {}, lr {}'.format(\n",
    "                datetime.datetime.now(),\n",
    "                epoch,\n",
    "                loss / len(train_loader),\n",
    "                validation_loss,\n",
    "                scheduler.get_last_lr())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "torch.version.cuda\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-05 01:03:43.867007 Epoch 0, Training loss 0.002523114439100027, Validation loss 1.7332574129104614, lr [0.001]\n",
      "2024-04-05 01:04:37.606964 Epoch 1, Training loss 0.0025311585050076246, Validation loss 1.7103959321975708, lr [0.001]\n",
      "2024-04-05 01:08:07.637600 Epoch 5, Training loss 0.002430521184578538, Validation loss 1.6840683221817017, lr [0.001]\n",
      "2024-04-05 01:12:29.915653 Epoch 10, Training loss 0.002282110508531332, Validation loss 1.660799264907837, lr [0.001]\n",
      "2024-04-05 01:16:55.646888 Epoch 15, Training loss 0.0022301622666418552, Validation loss 1.6460583209991455, lr [0.001]\n",
      "2024-04-05 01:21:30.931399 Epoch 20, Training loss 0.0021963517647236586, Validation loss 1.6361205577850342, lr [0.001]\n",
      "2024-04-05 01:26:07.401950 Epoch 25, Training loss 0.0021739790681749582, Validation loss 1.6288881301879883, lr [0.001]\n",
      "2024-04-05 01:30:42.214079 Epoch 30, Training loss 0.0021605573128908873, Validation loss 1.62420654296875, lr [0.0001]\n",
      "2024-04-05 01:35:17.513530 Epoch 35, Training loss 0.0021581584587693214, Validation loss 1.6235326528549194, lr [0.0001]\n",
      "2024-04-05 01:39:52.865308 Epoch 40, Training loss 0.0021566771902143955, Validation loss 1.6230347156524658, lr [0.0001]\n",
      "2024-04-05 01:44:28.694119 Epoch 45, Training loss 0.0021553642582148314, Validation loss 1.6225632429122925, lr [0.0001]\n",
      "2024-04-05 01:49:05.110349 Epoch 50, Training loss 0.002154119312763214, Validation loss 1.6221030950546265, lr [0.0001]\n",
      "2024-04-05 01:53:40.686625 Epoch 55, Training loss 0.002152920002117753, Validation loss 1.6216545104980469, lr [0.0001]\n",
      "2024-04-05 01:58:18.601885 Epoch 60, Training loss 0.0021519362926483154, Validation loss 1.621289610862732, lr [1e-05]\n",
      "2024-04-05 02:02:52.637465 Epoch 65, Training loss 0.0021517721470445395, Validation loss 1.62123703956604, lr [1e-05]\n",
      "2024-04-05 02:07:27.956186 Epoch 70, Training loss 0.0021516182459890842, Validation loss 1.6211861371994019, lr [1e-05]\n",
      "2024-04-05 02:12:04.380010 Epoch 75, Training loss 0.0021514727268368006, Validation loss 1.6211377382278442, lr [1e-05]\n",
      "2024-04-05 02:16:43.268441 Epoch 80, Training loss 0.002151334658265114, Validation loss 1.6210906505584717, lr [1e-05]\n",
      "2024-04-05 02:21:19.841711 Epoch 85, Training loss 0.0021512017119675875, Validation loss 1.62104332447052, lr [1e-05]\n",
      "2024-04-05 02:25:58.514042 Epoch 90, Training loss 0.002151094377040863, Validation loss 1.621006727218628, lr [1.0000000000000002e-06]\n",
      "2024-04-05 02:30:32.629258 Epoch 95, Training loss 0.0021510813385248184, Validation loss 1.6210020780563354, lr [1.0000000000000002e-06]\n",
      "2024-04-05 02:35:50.176882 Epoch 0, Training loss 0.0032775267027318478, Validation loss 2.402839422225952, lr [0.001]\n",
      "2024-04-05 02:37:28.137286 Epoch 1, Training loss 0.003247223561629653, Validation loss 2.3821234703063965, lr [0.001]\n",
      "2024-04-05 02:43:59.321861 Epoch 5, Training loss 0.003196784295141697, Validation loss 2.353708505630493, lr [0.001]\n",
      "2024-04-05 02:52:08.775385 Epoch 10, Training loss 0.0031678329687565565, Validation loss 2.3388466835021973, lr [0.001]\n",
      "2024-04-05 03:00:19.474274 Epoch 15, Training loss 0.0031511434353888035, Validation loss 2.331146717071533, lr [0.001]\n",
      "2024-04-05 03:08:28.951851 Epoch 20, Training loss 0.0031411517411470413, Validation loss 2.3265116214752197, lr [0.001]\n",
      "2024-04-05 03:16:39.970985 Epoch 25, Training loss 0.003134737489745021, Validation loss 2.3231585025787354, lr [0.001]\n",
      "2024-04-05 03:24:49.304923 Epoch 30, Training loss 0.003130377968773246, Validation loss 2.320924758911133, lr [0.0001]\n",
      "2024-04-05 03:33:00.580821 Epoch 35, Training loss 0.0031295730732381344, Validation loss 2.3205771446228027, lr [0.0001]\n",
      "2024-04-05 03:41:11.339760 Epoch 40, Training loss 0.00312890880741179, Validation loss 2.3203232288360596, lr [0.0001]\n",
      "2024-04-05 03:49:19.386982 Epoch 45, Training loss 0.003128310665488243, Validation loss 2.3200905323028564, lr [0.0001]\n",
      "2024-04-05 03:57:28.288310 Epoch 50, Training loss 0.0031277344096451998, Validation loss 2.319868326187134, lr [0.0001]\n",
      "2024-04-05 04:05:39.169933 Epoch 55, Training loss 0.0031271621119230986, Validation loss 2.3196539878845215, lr [0.0001]\n",
      "2024-04-05 04:13:45.981436 Epoch 60, Training loss 0.003126683412119746, Validation loss 2.319481372833252, lr [1e-05]\n",
      "2024-04-05 04:21:56.708794 Epoch 65, Training loss 0.003126623574644327, Validation loss 2.319458246231079, lr [1e-05]\n",
      "2024-04-05 04:30:08.059401 Epoch 70, Training loss 0.003126563271507621, Validation loss 2.3194358348846436, lr [1e-05]\n",
      "2024-04-05 04:38:46.392527 Epoch 75, Training loss 0.003126502735540271, Validation loss 2.319413661956787, lr [1e-05]\n",
      "2024-04-05 04:46:47.212477 Epoch 80, Training loss 0.0031264417339116335, Validation loss 2.3193917274475098, lr [1e-05]\n",
      "2024-04-05 04:54:24.863205 Epoch 85, Training loss 0.00312638096511364, Validation loss 2.319370746612549, lr [1e-05]\n",
      "2024-04-05 05:02:38.267696 Epoch 90, Training loss 0.003126330440863967, Validation loss 2.3193531036376953, lr [1.0000000000000002e-06]\n",
      "2024-04-05 05:10:52.370677 Epoch 95, Training loss 0.0031263246200978756, Validation loss 2.3193509578704834, lr [1.0000000000000002e-06]\n",
      "2024-04-05 05:18:10.446207 Epoch 0, Training loss 0.002425229176878929, Validation loss 1.7492916584014893, lr [0.001]\n",
      "2024-04-05 05:18:56.128830 Epoch 1, Training loss 0.0024241446517407894, Validation loss 1.7327038049697876, lr [0.001]\n",
      "2024-04-05 05:22:02.930407 Epoch 5, Training loss 0.002397674834355712, Validation loss 1.7108098268508911, lr [0.001]\n",
      "2024-04-05 05:25:55.262448 Epoch 10, Training loss 0.0023760367184877396, Validation loss 1.6913317441940308, lr [0.001]\n",
      "2024-04-05 05:29:55.155599 Epoch 15, Training loss 0.0023474593181163073, Validation loss 1.6667836904525757, lr [0.001]\n",
      "2024-04-05 05:33:47.271898 Epoch 20, Training loss 0.0023273031692951918, Validation loss 1.6545995473861694, lr [0.001]\n",
      "2024-04-05 05:37:39.088341 Epoch 25, Training loss 0.0023126171436160803, Validation loss 1.646706461906433, lr [0.001]\n",
      "2024-04-05 05:41:30.337484 Epoch 30, Training loss 0.0023023905232548714, Validation loss 1.6419553756713867, lr [0.0001]\n",
      "2024-04-05 05:45:19.885325 Epoch 35, Training loss 0.0023005858529359102, Validation loss 1.641343116760254, lr [0.0001]\n",
      "2024-04-05 05:49:11.431801 Epoch 40, Training loss 0.0022992913145571947, Validation loss 1.6408398151397705, lr [0.0001]\n",
      "2024-04-05 05:53:03.602243 Epoch 45, Training loss 0.002298199338838458, Validation loss 1.6403687000274658, lr [0.0001]\n",
      "2024-04-05 05:56:56.753930 Epoch 50, Training loss 0.0022971821017563343, Validation loss 1.6399154663085938, lr [0.0001]\n",
      "2024-04-05 06:00:50.355934 Epoch 55, Training loss 0.0022962018847465515, Validation loss 1.6394766569137573, lr [0.0001]\n",
      "2024-04-05 06:04:41.646960 Epoch 60, Training loss 0.002295400481671095, Validation loss 1.6391271352767944, lr [1e-05]\n",
      "2024-04-05 06:08:33.075355 Epoch 65, Training loss 0.0022952936124056578, Validation loss 1.639082670211792, lr [1e-05]\n",
      "2024-04-05 06:12:24.545238 Epoch 70, Training loss 0.0022951869759708643, Validation loss 1.6390377283096313, lr [1e-05]\n",
      "2024-04-05 06:16:16.789617 Epoch 75, Training loss 0.0022950812708586454, Validation loss 1.6389939785003662, lr [1e-05]\n",
      "2024-04-05 06:20:07.272647 Epoch 80, Training loss 0.002294976729899645, Validation loss 1.638951063156128, lr [1e-05]\n",
      "2024-04-05 06:24:00.012090 Epoch 85, Training loss 0.002294873120263219, Validation loss 1.6389082670211792, lr [1e-05]\n",
      "2024-04-05 06:27:51.878616 Epoch 90, Training loss 0.002294787671416998, Validation loss 1.6388739347457886, lr [1.0000000000000002e-06]\n",
      "2024-04-05 06:31:43.924959 Epoch 95, Training loss 0.0022947771940380335, Validation loss 1.6388689279556274, lr [1.0000000000000002e-06]\n",
      "2024-04-05 06:37:18.610202 Epoch 0, Training loss 0.0023021542001515627, Validation loss 1.735213041305542, lr [0.001]\n",
      "2024-04-05 06:39:48.604028 Epoch 1, Training loss 0.002302478300407529, Validation loss 1.7095779180526733, lr [0.001]\n",
      "2024-04-05 06:49:44.220076 Epoch 5, Training loss 0.002315628109499812, Validation loss 1.6629430055618286, lr [0.001]\n",
      "2024-04-05 07:02:12.655499 Epoch 10, Training loss 0.002316814148798585, Validation loss 1.633618712425232, lr [0.001]\n",
      "2024-04-05 07:14:45.728610 Epoch 15, Training loss 0.002305656671524048, Validation loss 1.6155717372894287, lr [0.001]\n",
      "2024-04-05 07:27:19.856222 Epoch 20, Training loss 0.002295758808031678, Validation loss 1.6044541597366333, lr [0.001]\n",
      "2024-04-05 07:39:52.245097 Epoch 25, Training loss 0.0022895261645317078, Validation loss 1.5974560976028442, lr [0.001]\n",
      "2024-04-05 07:52:21.992123 Epoch 30, Training loss 0.0022848572116345167, Validation loss 1.593461036682129, lr [0.0001]\n",
      "2024-04-05 08:04:51.143543 Epoch 35, Training loss 0.0022822488099336624, Validation loss 1.5928504467010498, lr [0.0001]\n",
      "2024-04-05 08:17:18.803718 Epoch 40, Training loss 0.0022812471725046635, Validation loss 1.592401385307312, lr [0.0001]\n",
      "2024-04-05 08:30:07.368043 Epoch 45, Training loss 0.0022806692868471146, Validation loss 1.5920019149780273, lr [0.0001]\n",
      "2024-04-05 08:42:44.205720 Epoch 50, Training loss 0.002280219690874219, Validation loss 1.591626763343811, lr [0.0001]\n",
      "2024-04-05 08:55:13.909773 Epoch 55, Training loss 0.0022798189893364906, Validation loss 1.591265320777893, lr [0.0001]\n",
      "2024-04-05 09:07:39.717562 Epoch 60, Training loss 0.0022794841788709164, Validation loss 1.5909771919250488, lr [1e-05]\n",
      "2024-04-05 09:21:51.101950 Epoch 65, Training loss 0.002279396401718259, Validation loss 1.5909380912780762, lr [1e-05]\n",
      "2024-04-05 09:35:44.655801 Epoch 70, Training loss 0.002279315609484911, Validation loss 1.5909005403518677, lr [1e-05]\n",
      "2024-04-05 09:50:26.028429 Epoch 75, Training loss 0.002279240172356367, Validation loss 1.5908632278442383, lr [1e-05]\n",
      "2024-04-05 10:03:45.302347 Epoch 80, Training loss 0.0022791700903326273, Validation loss 1.5908266305923462, lr [1e-05]\n",
      "2024-04-05 10:18:35.713029 Epoch 85, Training loss 0.0022791041992604733, Validation loss 1.5907902717590332, lr [1e-05]\n",
      "2024-04-05 10:33:32.889662 Epoch 90, Training loss 0.0022790515795350075, Validation loss 1.5907610654830933, lr [1.0000000000000002e-06]\n",
      "2024-04-05 10:49:29.935928 Epoch 95, Training loss 0.002279045293107629, Validation loss 1.5907574892044067, lr [1.0000000000000002e-06]\n"
     ]
    }
   ],
   "source": [
    "input_size = 9\n",
    "num_layers = 1\n",
    "hidden_size = 6\n",
    "\n",
    "\n",
    "rnn_models = {\"classic RNN\": SimpleRNN(input_size, num_layers, hidden_size),\n",
    "              \"bidirectional RNN\": BidirectionalRNN(input_size, num_layers, hidden_size),\n",
    "              \"LSTM RNN\": LSTMRNN(input_size, num_layers, hidden_size),\n",
    "              \"GRU RNN\": GRURNN(input_size, num_layers, hidden_size),\n",
    "              }\n",
    "\n",
    "for name, model in rnn_models.items():\n",
    "    model = model.to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=30)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    training_loop(100, optimizer=optimizer, scheduler=lr_scheduler, model=model, loss_fn=loss_fn, train_loader=train_loader, validation_loader=validation_loader)\n",
    "    torch.save(model.state_dict(), f\"{name}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
